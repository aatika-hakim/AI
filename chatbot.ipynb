{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbVnjzquf2bd21E3oNLWIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aatika-hakim/AI/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86bW3iUZQ2nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "iSXuN84DQigR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "6CGpFizLQjRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "_-C5Znl7Qnqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")\n",
        "llm.invoke(\"hi\").content"
      ],
      "metadata": {
        "id": "1gtx7uE9QqGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "2vPPqD0hQxcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "hmeg7EfPQ738"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "id": "W7UL2T5YRA_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "tool.invoke(\"What's a 'node' in LangGraph?\")"
      ],
      "metadata": {
        "id": "QWFuLGMGRHw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "id": "rQYoZL_9RJFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "id": "VH7wxmoMROR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "\n",
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "n6ZnbODgRRmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "id": "6O2jYq7KRWRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "id": "ppVhrktdRaFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "6V-8S8zHReX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}