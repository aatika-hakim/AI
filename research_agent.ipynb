{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlTXelDxn9boOTY1xFXV+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aatika-hakim/AI/blob/main/research_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EdyxYQtUSm7"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet langchain langchain-community langgraph langchain_google_genai pdfplumber langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q pydantic"
      ],
      "metadata": {
        "id": "UC17WVO4Wm9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import urllib3\n",
        "import pdfplumber\n",
        "from IPython.display import display, Markdown\n",
        "# from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage, AIMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, Annotated, Sequence, ClassVar, TypedDict\n",
        "\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "# os.environ['CORE_API_KEY'] = userdata.get('CORE_API_KEY')"
      ],
      "metadata": {
        "id": "SZuRsgB2Uwsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for the initial decision making on how to reply to the user\n",
        "decision_making_prompt = \"\"\"\n",
        "You are an experienced scientific researcher.\n",
        "Your goal is to help the user with their scientific research.\n",
        "\n",
        "Based on the user query, decide if you need to perform a research or if you can answer the question directly.\n",
        "- You should perform a research if the user query requires any supporting evidence or information.\n",
        "- You should answer the question directly only for simple conversational questions, like \"how are you?\".\n",
        "\"\"\"\n",
        "\n",
        "# Prompt to create a step by step plan to answer the user query\n",
        "planning_prompt = \"\"\"\n",
        "# IDENTITY AND PURPOSE\n",
        "\n",
        "You are an experienced scientific researcher.\n",
        "Your goal is to make a new step by step plan to help the user with their scientific research .\n",
        "\n",
        "Subtasks should not rely on any assumptions or guesses, but only rely on the information provided in the context or look up for any additional information.\n",
        "\n",
        "If any feedback is provided about a previous answer, incorportate it in your new planning.\n",
        "\n",
        "\n",
        "# TOOLS\n",
        "\n",
        "For each subtask, indicate the external tool required to complete the subtask.\n",
        "Tools can be one of the following:\n",
        "{tools}\n",
        "\"\"\"\n",
        "\n",
        "# Prompt for the agent to answer the user query\n",
        "agent_prompt = \"\"\"\n",
        "# IDENTITY AND PURPOSE\n",
        "\n",
        "You are an experienced scientific researcher.\n",
        "Your goal is to help the user with their scientific research. You have access to a set of external tools to complete your tasks.\n",
        "Follow the plan you wrote to successfully complete the task.\n",
        "\n",
        "Add extensive inline citations to support any claim made in the answer.\n",
        "\n",
        "\n",
        "# EXTERNAL KNOWLEDGE\n",
        "\n",
        "## CORE API\n",
        "\n",
        "The CORE API has a specific query language that allows you to explore a vast papers collection and perform complex queries. See the following table for a list of available operators:\n",
        "\n",
        "| Operator       | Accepted symbols         | Meaning                                                                                      |\n",
        "|---------------|-------------------------|----------------------------------------------------------------------------------------------|\n",
        "| And           | AND, +, space          | Logical binary and.                                                                           |\n",
        "| Or            | OR                     | Logical binary or.                                                                            |\n",
        "| Grouping      | (...)                  | Used to prioritise and group elements of the query.                                           |\n",
        "| Field lookup  | field_name:value       | Used to support lookup of specific fields.                                                    |\n",
        "| Range queries | fieldName(>, <,>=, <=) | For numeric and date fields, it allows to specify a range of valid values to return.         |\n",
        "| Exists queries| _exists_:fieldName     | Allows for complex queries, it returns all the items where the field specified by fieldName is not empty. |\n",
        "\n",
        "Use this table to formulate more complex queries filtering for specific papers, for example publication date/year.\n",
        "Here are the relevant fields of a paper object you can use to filter the results:\n",
        "{\n",
        "  \"authors\": [{\"name\": \"Last Name, First Name\"}],\n",
        "  \"documentType\": \"presentation\" or \"research\" or \"thesis\",\n",
        "  \"publishedDate\": \"2019-08-24T14:15:22Z\",\n",
        "  \"title\": \"Title of the paper\",\n",
        "  \"yearPublished\": \"2019\"\n",
        "}\n",
        "\n",
        "Example queries:\n",
        "- \"machine learning AND yearPublished:2023\"\n",
        "- \"maritime biology AND yearPublished>=2023 AND yearPublished<=2024\"\n",
        "- \"cancer research AND authors:Vaswani, Ashish AND authors:Bello, Irwan\"\n",
        "- \"title:Attention is all you need\"\n",
        "- \"mathematics AND _exists_:abstract\"\n",
        "\"\"\"\n",
        "\n",
        "# Prompt for the judging step to evaluate the quality of the final answer\n",
        "judge_prompt = \"\"\"\n",
        "You are an expert scientific researcher.\n",
        "Your goal is to review the final answer you provided for a specific user query.\n",
        "\n",
        "Look at the conversation history between you and the user. Based on it, you need to decide if the final answer is satisfactory or not.\n",
        "\n",
        "A good final answer should:\n",
        "- Directly answer the user query. For example, it does not answer a question about a different paper or area of research.\n",
        "- Answer extensively the request from the user.\n",
        "- Take into account any feedback given through the conversation.\n",
        "- Provide inline sources to support any claim made in the answer.\n",
        "\n",
        "In case the answer is not good enough, provide clear and concise feedback on what needs to be improved to pass the evaluation.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SDf7DKl7Zx6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class CoreAPIWrapper(BaseModel):\n",
        "#     \"\"\"Simple wrapper around the CORE API.\"\"\"\n",
        "#     base_url: ClassVar[str] = \"https://api.core.ac.uk/v3\"\n",
        "#     api_key: ClassVar[str] = os.environ[\"CORE_API_KEY\"]\n",
        "\n",
        "#     top_k_results: int = Field(description = \"Top k results obtained by running a query on Core\", default = 1)\n",
        "\n",
        "#     def _get_search_response(self, query: str) -> dict:\n",
        "#         http = urllib3.PoolManager()\n",
        "\n",
        "#         # Retry mechanism to handle transient errors\n",
        "#         max_retries = 5\n",
        "#         for attempt in range(max_retries):\n",
        "#             response = http.request(\n",
        "#                 'GET',\n",
        "#                 f\"{self.base_url}/search/outputs\",\n",
        "#                 headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
        "#                 fields={\"q\": query, \"limit\": self.top_k_results}\n",
        "#             )\n",
        "#             if 200 <= response.status < 300:\n",
        "#                 return response.json()\n",
        "#             elif attempt < max_retries - 1:\n",
        "#                 time.sleep(2 ** (attempt + 2))\n",
        "#             else:\n",
        "#                 raise Exception(f\"Got non 2xx response from CORE API: {response.status} {response.data}\")\n",
        "\n",
        "#     def search(self, query: str) -> str:\n",
        "#         response = self._get_search_response(query)\n",
        "#         results = response.get(\"results\", [])\n",
        "#         if not results:\n",
        "#             return \"No relevant results were found\"\n",
        "\n",
        "#         # Format the results in a string\n",
        "#         docs = []\n",
        "#         for result in results:\n",
        "#             published_date_str = result.get('publishedDate') or result.get('yearPublished', '')\n",
        "#             authors_str = ' and '.join([item['name'] for item in result.get('authors', [])])\n",
        "#             docs.append((\n",
        "#                 f\"* ID: {result.get('id', '')},\\n\"\n",
        "#                 f\"* Title: {result.get('title', '')},\\n\"\n",
        "#                 f\"* Published Date: {published_date_str},\\n\"\n",
        "#                 f\"* Authors: {authors_str},\\n\"\n",
        "#                 f\"* Abstract: {result.get('abstract', '')},\\n\"\n",
        "#                 f\"* Paper URLs: {result.get('sourceFulltextUrls') or result.get('downloadUrl', '')}\"\n",
        "#             ))\n",
        "#         return \"\\n-----\\n\".join(docs)\n",
        "\n",
        "class SearchPapersInput(BaseModel):\n",
        "    \"\"\"Input object to search papers with the CORE API.\"\"\"\n",
        "    query: str = Field(description=\"The query to search for on the selected archive.\")\n",
        "    max_papers: int = Field(description=\"The maximum number of papers to return. It's default to 1, but you can increase it up to 10 in case you need to perform a more comprehensive search.\", default=1, ge=1, le=10)\n",
        "\n",
        "class DecisionMakingOutput(BaseModel):\n",
        "    \"\"\"Output object of the decision making node.\"\"\"\n",
        "    requires_research: bool = Field(description=\"Whether the user query requires research or not.\")\n",
        "    answer: Optional[str] = Field(default=None, description=\"The answer to the user query. It should be None if the user query requires research, otherwise it should be a direct answer to the user query.\")\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    \"\"\"Output object of the judge node.\"\"\"\n",
        "    is_good_answer: bool = Field(description=\"Whether the answer is good or not.\")\n",
        "    feedback: Optional[str] = Field(default=None, description=\"Detailed feedback about why the answer is not good. It should be None if the answer is good.\")\n",
        "\n",
        "def format_tools_description(tools: list[BaseTool]) -> str:\n",
        "    return \"\\n\\n\".join([f\"- {tool.name}: {tool.description}\\n Input arguments: {tool.args}\" for tool in tools])\n",
        "\n",
        "async def print_stream(app: CompiledStateGraph, input: str) -> Optional[BaseMessage]:\n",
        "    display(Markdown(\"## New research running\"))\n",
        "    display(Markdown(f\"### Input:\\n\\n{input}\\n\\n\"))\n",
        "    display(Markdown(\"### Stream:\\n\\n\"))\n",
        "\n",
        "    # Stream the results\n",
        "    all_messages = []\n",
        "    async for chunk in app.astream({\"messages\": [input]}, stream_mode=\"updates\"):\n",
        "        for updates in chunk.values():\n",
        "            if messages := updates.get(\"messages\"):\n",
        "                all_messages.extend(messages)\n",
        "                for message in messages:\n",
        "                    message.pretty_print()\n",
        "                    print(\"\\n\\n\")\n",
        "\n",
        "    # Return the last message if any\n",
        "    if not all_messages:\n",
        "        return None\n",
        "    return all_messages[-1]"
      ],
      "metadata": {
        "id": "dC6_fSwgaTlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"The state of the agent during the paper research process.\"\"\"\n",
        "requires_research: bool = False\n",
        "num_feedback_requests: int = 0\n",
        "is_good_answer: bool = False\n",
        "messages: Annotated[Sequence[BaseMessage], add_messages]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "xdL8KShJbfQA",
        "outputId": "56a2298a-9470-421b-82bd-50659753ef9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'add_messages' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bb4d7c46e795>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_feedback_requests\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mis_good_answer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_messages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'add_messages' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"search-papers\", args_schema=SearchPapersInput)\n",
        "def search_papers(query: str, max_papers: int = 1) -> str:\n",
        "    \"\"\"Search for scientific papers using the CORE API.\n",
        "\n",
        "    Example:\n",
        "    {\"query\": \"Attention is all you need\", \"max_papers\": 1}\n",
        "\n",
        "    Returns:\n",
        "        A list of the relevant papers found with the corresponding relevant information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return CoreAPIWrapper(top_k_results=max_papers).search(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error performing paper search: {e}\"\n",
        "\n",
        "@tool(\"download-paper\")\n",
        "def download_paper(url: str) -> str:\n",
        "    \"\"\"Download a specific scientific paper from a given URL.\n",
        "\n",
        "    Example:\n",
        "    {\"url\": \"https://www.forgottenbooks.com\"}\n",
        "\n",
        "    Returns:\n",
        "        The paper content.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        http = urllib3.PoolManager(\n",
        "            cert_reqs='CERT_NONE',\n",
        "        )\n",
        "\n",
        "        # Mock browser headers to avoid 403 error\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "            'Accept-Language': 'en-US,en;q=0.5',\n",
        "            'Accept-Encoding': 'gzip, deflate, br',\n",
        "            'Connection': 'keep-alive',\n",
        "        }\n",
        "        max_retries = 5\n",
        "        for attempt in range(max_retries):\n",
        "            response = http.request('GET', url, headers=headers)\n",
        "            if 200 <= response.status < 300:\n",
        "                pdf_file = io.BytesIO(response.data)\n",
        "                with pdfplumber.open(pdf_file) as pdf:\n",
        "                    text = \"\"\n",
        "                    for page in pdf.pages:\n",
        "                        text += page.extract_text() + \"\\n\"\n",
        "                return text\n",
        "            elif attempt < max_retries - 1:\n",
        "                time.sleep(2 ** (attempt + 2))\n",
        "            else:\n",
        "                raise Exception(f\"Got non 2xx when downloading paper: {response.status_code} {response.text}\")\n",
        "    except Exception as e:\n",
        "        return f\"Error downloading paper: {e}\"\n",
        "\n",
        "@tool(\"ask-human-feedback\")\n",
        "def ask_human_feedback(question: str) -> str:\n",
        "    \"\"\"Ask for human feedback. You should call this tool when encountering unexpected errors.\"\"\"\n",
        "    return input(question)\n",
        "\n",
        "tools = [search_papers, download_paper, ask_human_feedback]\n",
        "tools_dict = {tool.name: tool for tool in tools}"
      ],
      "metadata": {
        "id": "KuKMBKZDafkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMs\n",
        "base_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.0)\n",
        "decision_making_llm = base_llm.with_structured_output(DecisionMakingOutput)\n",
        "agent_llm = base_llm.bind_tools(tools)\n",
        "judge_llm = base_llm.with_structured_output(JudgeOutput)\n",
        "\n",
        "# Decision making node\n",
        "def decision_making_node(state: AgentState):\n",
        "    \"\"\"Entry point of the workflow. Based on the user query, the model can either respond directly or perform a full research, routing the workflow to the planning node\"\"\"\n",
        "    system_prompt = SystemMessage(content=decision_making_prompt)\n",
        "    response: DecisionMakingOutput = decision_making_llm.invoke([system_prompt] + state[\"messages\"])\n",
        "    output = {\"requires_research\": response.requires_research}\n",
        "    if response.answer:\n",
        "        output[\"messages\"] = [AIMessage(content=response.answer)]\n",
        "    return output\n",
        "\n",
        "# Task router function\n",
        "def router(state: AgentState):\n",
        "    \"\"\"Router directing the user query to the appropriate branch of the workflow.\"\"\"\n",
        "    if state[\"requires_research\"]:\n",
        "        return \"planning\"\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "# Planning node\n",
        "def planning_node(state: AgentState):\n",
        "    \"\"\"Planning node that creates a step by step plan to answer the user query.\"\"\"\n",
        "    system_prompt = SystemMessage(content=planning_prompt.format(tools=format_tools_description(tools)))\n",
        "    response = base_llm.invoke([system_prompt] + state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Tool call node\n",
        "def tools_node(state: AgentState):\n",
        "    \"\"\"Tool call node that executes the tools based on the plan.\"\"\"\n",
        "    outputs = []\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        tool_result = tools_dict[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
        "        outputs.append(\n",
        "            ToolMessage(\n",
        "                content=json.dumps(tool_result),\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "    return {\"messages\": outputs}\n",
        "\n",
        "# Agent call node\n",
        "def agent_node(state: AgentState):\n",
        "    \"\"\"Agent call node that uses the LLM with tools to answer the user query.\"\"\"\n",
        "    system_prompt = SystemMessage(content=agent_prompt)\n",
        "    response = agent_llm.invoke([system_prompt] + state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Should continue function\n",
        "def should_continue(state: AgentState):\n",
        "    \"\"\"Check if the agent should continue or end.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    # End execution if there are no tool calls\n",
        "    if last_message.tool_calls:\n",
        "        return \"continue\"\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "# Judge node\n",
        "def judge_node(state: AgentState):\n",
        "    \"\"\"Node to let the LLM judge the quality of its own final answer.\"\"\"\n",
        "    # End execution if the LLM failed to provide a good answer twice.\n",
        "    num_feedback_requests = state.get(\"num_feedback_requests\", 0)\n",
        "    if num_feedback_requests >= 2:\n",
        "        return {\"is_good_answer\": True}\n",
        "\n",
        "    system_prompt = SystemMessage(content=judge_prompt)\n",
        "    response: JudgeOutput = judge_llm.invoke([system_prompt] + state[\"messages\"])\n",
        "    output = {\n",
        "        \"is_good_answer\": response.is_good_answer,\n",
        "        \"num_feedback_requests\": num_feedback_requests + 1\n",
        "    }\n",
        "    if response.feedback:\n",
        "        output[\"messages\"] = [AIMessage(content=response.feedback)]\n",
        "    return output\n",
        "\n",
        "# Final answer router function\n",
        "def final_answer_router(state: AgentState):\n",
        "    \"\"\"Router to end the workflow or improve the answer.\"\"\"\n",
        "    if state[\"is_good_answer\"]:\n",
        "        return \"end\"\n",
        "    else:\n",
        "        return \"planning\""
      ],
      "metadata": {
        "id": "jIZ8BiuMatvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the StateGraph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"decision_making\", decision_making_node)\n",
        "workflow.add_node(\"planning\", planning_node)\n",
        "workflow.add_node(\"tools\", tools_node)\n",
        "workflow.add_node(\"agent\", agent_node)\n",
        "workflow.add_node(\"judge\", judge_node)\n",
        "\n",
        "# Set the entry point of the graph\n",
        "workflow.set_entry_point(\"decision_making\")\n",
        "\n",
        "# Add edges between nodes\n",
        "workflow.add_conditional_edges(\n",
        "    \"decision_making\",\n",
        "    router,\n",
        "    {\n",
        "        \"planning\": \"planning\",\n",
        "        \"end\": END,\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"planning\", \"agent\")\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"tools\",\n",
        "        \"end\": \"judge\",\n",
        "    },\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"judge\",\n",
        "    final_answer_router,\n",
        "    {\n",
        "        \"planning\": \"planning\",\n",
        "        \"end\": END,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "oGxbAidBbr5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs = [\n",
        "    \"Download and summarize the findings of this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11379842/pdf/11671_2024_Article_4070.pdf\",\n",
        "\n",
        "    \"Can you find 8 papers on quantum machine learning?\",\n",
        "\n",
        "    \"\"\"Find recent papers (2023-2024) about CRISPR applications in treating genetic disorders,\n",
        "    focusing on clinical trials and safety protocols\"\"\",\n",
        "\n",
        "    \"\"\"Find and analyze papers from 2023-2024 about the application of transformer architectures in protein folding prediction,\n",
        "    specifically looking for novel architectural modifications with experimental validation.\"\"\"\n",
        "]\n",
        "\n",
        "# Run tests and store the results for later visualisation\n",
        "outputs = []\n",
        "for test_input in test_inputs:\n",
        "    final_answer = await print_stream(app, test_input)\n",
        "    outputs.append(final_answer.content)\n"
      ],
      "metadata": {
        "id": "IlXXxWsAbxfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3kvih7YbsDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}